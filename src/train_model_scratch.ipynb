{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'\n",
    "data_dict = joblib.load(os.path.join(data_path, 'data_dict.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key = starting state, value = next state\n",
    "transition_dict_train = dict(zip(data_dict['train']['state_id'], data_dict['train']['next_state_id']))\n",
    "transition_dict_val = dict(zip(data_dict['val']['state_id'], data_dict['val']['next_state_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "              'state_dim' : data_dict['train']['X'].shape[1],\n",
    "              'action_dim' : 25,\n",
    "              'gamma' : 0.9,\n",
    "              'batch_size' : 512,\n",
    "              'lr' : 1e-4,\n",
    "              'num_epochs' : 100,\n",
    "              'hidden_dim' : 24,\n",
    "              'num_hidden' : 5,\n",
    "              'drop_prob' : 0.0,\n",
    "              'target_update': 10,\n",
    "              'option' : 'linear',\n",
    "              'use_scheduler' : False\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153569, 46)\n",
      "(19540, 46)\n"
     ]
    }
   ],
   "source": [
    "print(data_dict['train']['X'].shape)\n",
    "print(data_dict['val']['X'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset\n",
    "train_dataset = RL_Dataset(data_dict['train']['X'], \n",
    "                           data_dict['train']['action'],\n",
    "                           data_dict['train']['reward'],\n",
    "                           transition_dict_train)\n",
    "\n",
    "val_dataset = RL_Dataset(data_dict['val']['X'], \n",
    "                           data_dict['val']['action'],\n",
    "                           data_dict['val']['reward'],\n",
    "                           transition_dict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                        config['batch_size'],\n",
    "                        shuffle = True,\n",
    "                        num_workers = 32\n",
    "#                         collate_fn = my_collate\n",
    "                         )\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                         config['batch_size'],\n",
    "                         shuffle = True,\n",
    "                         num_workers = 32\n",
    "#                         collate_fn = my_collate\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 0/99\n",
      "----------\n",
      "Updating Target Model\n",
      "train Loss: 1.423674, Best Value: 0.635803, Empirical Value: -0.194977\n",
      "val Loss: 1.591676, Best Value: 0.607954, Empirical Value: -0.159891\n",
      "Best Value updated\n",
      "----------\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 1.444079, Best Value: 0.804370, Empirical Value: 0.150163\n",
      "val Loss: 1.328656, Best Value: 0.925831, Empirical Value: 0.350447\n",
      "Best Value updated\n",
      "----------\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 1.339452, Best Value: 0.961703, Empirical Value: 0.447062\n",
      "val Loss: 1.297089, Best Value: 0.983865, Empirical Value: 0.503225\n",
      "Best Value updated\n",
      "----------\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 1.324837, Best Value: 0.963877, Empirical Value: 0.522545\n",
      "val Loss: 1.290932, Best Value: 0.935136, Empirical Value: 0.521515\n",
      "----------\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 1.320989, Best Value: 0.919744, Empirical Value: 0.527066\n",
      "val Loss: 1.288822, Best Value: 0.898995, Empirical Value: 0.520884\n",
      "----------\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 1.319315, Best Value: 0.871553, Empirical Value: 0.514113\n",
      "val Loss: 1.288158, Best Value: 0.845827, Empirical Value: 0.503388\n",
      "----------\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 1.318191, Best Value: 0.831368, Empirical Value: 0.502121\n",
      "val Loss: 1.287236, Best Value: 0.810955, Empirical Value: 0.495433\n",
      "----------\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 1.318061, Best Value: 0.793778, Empirical Value: 0.485985\n",
      "val Loss: 1.287418, Best Value: 0.775126, Empirical Value: 0.475209\n",
      "----------\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 1.318447, Best Value: 0.762179, Empirical Value: 0.468394\n",
      "val Loss: 1.288917, Best Value: 0.744671, Empirical Value: 0.454635\n",
      "----------\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 1.319257, Best Value: 0.731601, Empirical Value: 0.445531\n",
      "val Loss: 1.289922, Best Value: 0.713494, Empirical Value: 0.428794\n",
      "----------\n",
      "Epoch 10/99\n",
      "----------\n",
      "Updating Target Model\n",
      "train Loss: 1.319861, Best Value: 0.704277, Empirical Value: 0.422459\n",
      "val Loss: 1.306960, Best Value: 0.685088, Empirical Value: 0.404793\n",
      "----------\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 1.305425, Best Value: 0.839586, Empirical Value: 0.622778\n",
      "val Loss: 1.268430, Best Value: 0.868388, Empirical Value: 0.667601\n",
      "----------\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 1.299925, Best Value: 0.869517, Empirical Value: 0.672292\n",
      "val Loss: 1.267623, Best Value: 0.856973, Empirical Value: 0.663327\n",
      "----------\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 1.299199, Best Value: 0.865962, Empirical Value: 0.671586\n",
      "val Loss: 1.267353, Best Value: 0.855484, Empirical Value: 0.662442\n",
      "----------\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 1.298850, Best Value: 0.862327, Empirical Value: 0.669679\n",
      "val Loss: 1.266868, Best Value: 0.853059, Empirical Value: 0.661825\n",
      "----------\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 1.298476, Best Value: 0.859582, Empirical Value: 0.667468\n",
      "val Loss: 1.266937, Best Value: 0.849596, Empirical Value: 0.662380\n",
      "----------\n",
      "Epoch 16/99\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "loaders = {'train' : train_loader,\n",
    "           'val' : val_loader\n",
    "          }\n",
    "\n",
    "dset_sizes = {'train' : len(train_dataset),\n",
    "              'val' : len(val_dataset)\n",
    "             }\n",
    "\n",
    "\n",
    "model = dueling_net(D_in = config['state_dim'], \n",
    "                    H = config['hidden_dim'], \n",
    "                    D_out = config['action_dim'],\n",
    "                    drop_prob = config['drop_prob'],\n",
    "                    num_hidden = config['num_hidden'],\n",
    "                    option = config['option']\n",
    "                   )\n",
    "\n",
    "target_model = dueling_net(D_in = config['state_dim'], \n",
    "                            H = config['hidden_dim'], \n",
    "                            D_out = config['action_dim'],\n",
    "                            drop_prob = config['drop_prob'],\n",
    "                            num_hidden = config['num_hidden'],\n",
    "                            option = config['option']\n",
    "                          )\n",
    "\n",
    "optimizer = optim.Adam([{'params': model.parameters()}], \n",
    "                        lr = config['lr'])\n",
    "\n",
    "if config['use_scheduler']:\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', verbose = True)\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "def weights_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform(m.weight.data).float()\n",
    "\n",
    "model.apply(weights_init)\n",
    "target_model.apply(weights_init)\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    target_model.cuda()\n",
    "\n",
    "criterion = torch.nn.SmoothL1Loss(size_average = False)\n",
    "\n",
    "performance_dict, best_model, best_loss, time_elapsed = train_model_double(model = model, \n",
    "                                                                            target_model = target_model,\n",
    "                                                                            loaders = loaders, \n",
    "                                                                            dset_sizes = dset_sizes, \n",
    "                                                                            config = config, \n",
    "                                                                            criterion = criterion,\n",
    "                                                                            optimizer = optimizer,\n",
    "                                                                            scheduler = scheduler,\n",
    "                                                                            use_gpu = use_gpu)\n",
    "# loss_dict[name] = best_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
